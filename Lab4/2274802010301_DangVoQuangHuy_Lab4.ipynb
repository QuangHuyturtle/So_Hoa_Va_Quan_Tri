{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab4 - MỘT SỐ THUẬT TOÁN CƠ BẢN CỦA HỌC MÁY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = \"/Users/qytheturtle/Documents/HK3/Số hoá và quản trị thông tin số/Lab4/housing.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "print(df.head())\n",
    "\n",
    "# Xử lý dữ liệu\n",
    "df = df.dropna()  # Xóa các hàng có giá trị thiếu\n",
    "df = df.drop(\"ocean_proximity\", axis=1, errors=\"ignore\")  # Xóa cột không phải số nếu có\n",
    "\n",
    "# Chia dữ liệu thành biến đầu vào (X) và đầu ra (y)\n",
    "X = df.drop(\"median_house_value\", axis=1)  # Biến đầu vào\n",
    "y = df[\"median_house_value\"] / 100000  # Chia giá trị nhà để dễ đọc\n",
    "\n",
    "# Chia tập dữ liệu 80% huấn luyện, 20% kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Xây dựng và huấn luyện mô hình\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán và đánh giá mô hình\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R2 Score: {r2}\")\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Giá trị thực tế')\n",
    "plt.ylabel('Giá trị dự đoán')\n",
    "plt.title('Biểu đồ dự đoán giá nhà')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Đọc dữ liệu từ file CSV và đặt tên cột đúng thứ tự\n",
    "file_path = \"/Users/qytheturtle/Documents/HK3/Số hoá và quản trị thông tin số/Lab4/lab1data1.txt\"\n",
    "df = pd.read_csv(file_path, names=['number_of_hours_study', 'exam_score'], sep=\",\")\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "df = df.dropna()  # Xóa các hàng có giá trị thiếu\n",
    "\n",
    "# Chọn biến đầu vào là 'number_of_hours_study' và biến đầu ra là 'exam_score'\n",
    "X = df[['number_of_hours_study']]  # Phải là 2D array cho sklearn\n",
    "y = df['exam_score']\n",
    "\n",
    "# Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Khởi tạo và huấn luyện mô hình hồi quy tuyến tính\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán giá trị từ mô hình\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Vẽ scatter plot dữ liệu thực tế (Hiển thị toàn bộ dữ liệu)\n",
    "plt.scatter(X, y, label=\"Actual\", color=\"blue\")\n",
    "\n",
    "# Vẽ đường hồi quy tuyến tính (Dùng tập kiểm tra để dự đoán)\n",
    "plt.plot(X_test, y_pred, color=\"green\", label=\"Prediction\")\n",
    "\n",
    "# Thiết lập nhãn trục và tiêu đề\n",
    "plt.xlabel(\"Number of Hours Study\")  # Trục X là số giờ học\n",
    "plt.ylabel(\"Exam Score\")  # Trục Y là điểm số\n",
    "plt.title(\"Biểu đồ dự đoán số giờ học và điểm số\")\n",
    "plt.legend()\n",
    "\n",
    "# Đặt ticks trục X theo yêu cầu\n",
    "plt.xticks([5.0, 7.5, 10.0, 12.5, 15.0, 17.5, 20.0, 22.5])\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Hồi quy logistic\n",
    "#Phân loại nhị phân hoặc đa lớp dựa trên các đặc trưng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dữ liệu\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)  # Chuyển thành DataFrame\n",
    "y = pd.Series(data.target)  # Chuyển thành Series\n",
    "\n",
    "# Chia tập dữ liệu (75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Xây dựng và huấn luyện mô hình Logistic Regression\n",
    "model = LogisticRegression(max_iter=5000)  # Tăng số lần lặp để hội tụ\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Trực quan hóa Confusion Matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Ác tính', 'Lành tính'], yticklabels=['Ác tính', 'Lành tính'])\n",
    "plt.xlabel(\"Dự đoán\")\n",
    "plt.ylabel(\"Thực tế\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Vẽ biểu đồ trực quan hóa\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, label=\"Thực tế\", color=\"blue\", alpha=0.6)\n",
    "plt.scatter(range(len(y_pred)), y_pred, label=\"Dự đoán\", color=\"red\", alpha=0.6)\n",
    "plt.xlabel(\"Mẫu dữ liệu\")\n",
    "plt.ylabel(\"Phân loại (0: Ác tính, 1: Lành tính)\")\n",
    "plt.title(\"So sánh Giá trị Thực tế và Dự đoán\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Phân cụm dữ liệu sử dụng KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)\n",
    "X['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Trực quan hóa phân cụm\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X.iloc[:, 0], y=X.iloc[:, 1], hue=X['Cluster'], palette='coolwarm', alpha=0.6)\n",
    "plt.xlabel(data.feature_names[0])\n",
    "plt.ylabel(data.feature_names[1])\n",
    "plt.title(\"Phân cụm bằng KMeans\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sử dụng data Iris để phân cụm\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target \n",
    "\n",
    "#Áp dụng kmean với số cụm là 3\n",
    "kmeans= KMeans(n_clusters=3,random_state=42)\n",
    "kmeans.fit(X)\n",
    "y_Kmeans=kmeans.predict(X)\n",
    "\n",
    "#Sử dụng PCA để giảm chiều (Về nhà giải thích cho tôi ở bài tập về nhà )\n",
    "pca= PCA(n_components=2)#Giảm xuống còn 2 chiều\n",
    "X_pca=pca.fit_transform(X)\n",
    "\n",
    "#Trực quan hoá kết quả\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = '/Users/qytheturtle/Documents/HK3/Số hoá và quản trị thông tin số/Lab4/framingham.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Hiển thị 5 dòng đầu tiên của dataset\n",
    "print(\"Dữ liệu từ file:\")\n",
    "print(df.head())\n",
    "\n",
    "# Load dataset Iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "\n",
    "# Áp dụng KMeans với số cụm là 3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "y_Kmeans = kmeans.predict(X)\n",
    "\n",
    "# Sử dụng PCA để giảm chiều xuống còn 2\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Trực quan hóa kết quả phân cụm\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y_Kmeans, palette=\"viridis\", style=y, s=100)\n",
    "\n",
    "# Vẽ tâm cụm\n",
    "centroids_pca = pca.transform(kmeans.cluster_centers_)  # Chuyển tâm cụm về không gian PCA\n",
    "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], c='red', marker='X', s=200, label='Centroids')\n",
    "\n",
    "plt.title(\"K-Means clustering trên dữ liệu Iris (sử dụng PCA)\")\n",
    "plt.xlabel(\"Thành phần chính 1\")\n",
    "plt.ylabel(\"Thành phần chính 2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTVN:\n",
    "# 1: Cho tập dữ liệu đoán bệnh tim bằng hồi quy logistic\n",
    "\n",
    "# 2 : Ứng dụng thuật toán Kmean cho tập dữ liệu customer data, you can get in kanggle\n",
    "\n",
    "# 3 : Tìm hiểu về ma trận nhầm lẫn và đánh giá độ chính xác trên các bài tập lớn \n",
    "# tổng cộng các bạn sẽ có 3 bài lớn và 4 bài nhỏ cho next homework\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bài 1 BTVN\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df = pd.read_csv(\"/Users/qytheturtle/Documents/HK3/Số hoá và quản trị thông tin số/Lab4/heart.csv\")\n",
    "\n",
    "# Kiểm tra thông tin dữ liệu\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = df.drop(columns=['target'])  # Loại bỏ cột mục tiêu\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = df['target']\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra (80%-20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Xây dựng mô hình hồi quy logistic\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Độ chính xác: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Trực quan hóa ma trận tương quan\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Ma trận tương quan giữa các biến\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bài 2 BTVN\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv(\"/Users/qytheturtle/Documents/HK3/Số hoá và quản trị thông tin số/Lab4/Mall_Customers.csv\")\n",
    "\n",
    "# Xem 5 dòng đầu tiên\n",
    "print(data.head())\n",
    "print(data.columns)\n",
    "\n",
    "# Vẽ phân bố thu nhập và điểm chi tiêu\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=data['Annual_Income_(k$)'], y=data['Spending_Score'])\n",
    "plt.xlabel(\"Annual Income (k$)\")\n",
    "plt.ylabel(\"Spending Score\")\n",
    "plt.title(\"Phân bố Thu nhập và Điểm chi tiêu\")\n",
    "plt.show()\n",
    "\n",
    "# Chọn hai đặc trưng quan trọng\n",
    "X = data[['Annual_Income_(k$)', 'Spending_Score']]\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', n_init=10, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Vẽ biểu đồ Elbow Method\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.xlabel(\"Số cụm\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.title(\"Elbow Method để xác định số cụm tối ưu\")\n",
    "plt.show()\n",
    "\n",
    "# Áp dụng K-Means với số cụm K=5\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', n_init=10, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Xem kết quả phân cụm\n",
    "print(data.head())\n",
    "\n",
    "# Vẽ phân cụm\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=data['Annual_Income_(k$)'], y=data['Spending_Score'], hue=data['Cluster'], palette='viridis', s=100)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red', label='Centroids', marker='X')\n",
    "plt.xlabel(\"Annual Income (k$)\")\n",
    "plt.ylabel(\"Spending Score\")\n",
    "plt.title(\"Phân cụm khách hàng dựa trên Thu nhập và Điểm chi tiêu\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PCA là kỹ thuật giảm chiều dữ liệu phổ biến trong học máy và thống kê, giúp giảm số lượng biến trong tập dữ liệu mà vẫn giữ lại thông tin quan trọng nhất bằng cách biến đổi dữ liệu về các trục chính có phương sai lớn nhất.\n",
    "\n",
    "Lợi ích của PCA:\n",
    "-Giảm chiều dữ liệu\n",
    "-Loại bỏ nhiễu\n",
    "-Tránh hiện tượng đa cộng tuyến\n",
    "-Trực quan hóa dữ liệu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Tìm hiểu về ma trận nhầm lẫn và đánh giá độ chính xác:\n",
    "\n",
    "##Ma trận nhầm lẫn (Confusion Matrix) giúp đánh giá hiệu suất của mô hình phân loại bằng cách so sánh dự đoán của mô hình với giá trị thực tế\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
